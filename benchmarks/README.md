# pgsqlite Benchmarks

This directory contains performance benchmarks comparing direct SQLite access with PostgreSQL client access through pgsqlite.

## Overview

The benchmark suite measures the overhead introduced by the PostgreSQL wire protocol translation layer. It performs identical operations using both direct SQLite connections and PostgreSQL clients connecting through pgsqlite.

## Latest Performance Results (2025-08-12)

### Best Performance by Operation Type

#### Read Operations: psycopg3-text
- **SELECT**: 0.136ms (125x overhead) - **21.8x faster than psycopg2!**
- **SELECT (cached)**: 0.299ms (90x overhead) - **5.5x faster than psycopg2**
- **Recommendation**: Use psycopg3-text for read-heavy workloads

#### Write Operations: psycopg2
- **INSERT**: 0.185ms (107x overhead) - **3.6x faster than psycopg3**
- **UPDATE**: 0.057ms (45x overhead) - **1.5x faster than psycopg3**
- **DELETE**: 0.036ms (38x overhead) - **2.0x faster than psycopg3**
- **Recommendation**: Use psycopg2 for write-heavy workloads

### Driver Comparison
| Driver | SELECT (ms) | INSERT (ms) | UPDATE (ms) | DELETE (ms) | Best For |
|--------|------------|-------------|-------------|-------------|----------|
| psycopg3-text | **0.136** üèÜ | 0.661 | 0.084 | 0.072 | Read-heavy workloads |
| psycopg2 | 2.963 | **0.185** üèÜ | **0.057** üèÜ | **0.036** üèÜ | Write-heavy workloads |
| psycopg3-binary | 0.497 | 0.691 | 0.086 | 0.071 | Complex data types |

### Key Findings
- **psycopg3-text** dominates read performance with exceptional SELECT optimization
- **psycopg2** remains superior for write operations despite being legacy
- **psycopg3-binary** shows overhead that exceeds benefits for simple operations
- Binary protocol is fully functional but best suited for complex data types (BYTEA, arrays, etc.)

## Running Benchmarks

### Basic Usage

By default, benchmarks run using:
- **Unix domain sockets** for connection (lowest latency)
- **In-memory databases** to measure pure protocol overhead

```bash
# Run with default settings (1000 operations, Unix socket, in-memory)
./run_benchmark.sh

# Run with custom iterations
./run_benchmark.sh -i 5000

# Run with custom iterations and batch size
./run_benchmark.sh -i 10000 -b 200
```

### TCP Mode

To benchmark using TCP/IP connections instead of Unix sockets:

```bash
# Run benchmark using TCP
./run_benchmark.sh --tcp

# Combine with other options
./run_benchmark.sh --tcp -i 5000
```

### File-Based Mode

To benchmark with disk I/O included:

```bash
# Run benchmark using file-based databases
./run_benchmark.sh --file-based

# With custom settings
./run_benchmark.sh --file-based -i 10000
```

### Driver Comparison Mode

To compare performance across different PostgreSQL drivers:

```bash
# Run comprehensive comparison of all drivers (psycopg2, psycopg3-text, psycopg3-binary)
./run_driver_comparison.sh

# This will:
# 1. Build pgsqlite in release mode
# 2. Start pgsqlite server
# 3. Run benchmarks with psycopg2
# 4. Run benchmarks with psycopg3-text
# 5. Run benchmarks with psycopg3-binary
# 6. Display comparison results
```

You can also run individual driver benchmarks:

```bash
# Run with specific driver
poetry run python benchmark_drivers.py --driver psycopg3-binary --port 5432

# Available drivers:
# - psycopg2 (traditional, legacy)
# - psycopg3-text (modern, text protocol)
# - psycopg3-binary (modern, binary protocol - FASTEST)
```

## What's Measured

The benchmark performs mixed operations including:
- **CREATE TABLE**: Table creation with various data types
- **INSERT**: Adding new records with random data
- **UPDATE**: Modifying existing records
- **DELETE**: Removing records
- **SELECT**: Querying data with WHERE conditions

For each operation type, the benchmark tracks:
- Average execution time (milliseconds)
- Total execution time (seconds)
- Min/max/median times
- Overhead percentage (pgsqlite vs direct SQLite)

## Setup Requirements

1. **Poetry**: Python dependency management
   ```bash
   curl -sSL https://install.python-poetry.org | python3 -
   ```

2. **Python 3.8+**: Required for running the benchmark script

The `run_benchmark.sh` script handles:
- Building pgsqlite in release mode
- Setting up Python virtual environment
- Installing dependencies
- Starting/stopping the pgsqlite server
- Running the benchmark
- Cleanup

## Understanding Results

The benchmark output shows:
- **SQLite Avg**: Average time for direct SQLite operations
- **pgsqlite Avg**: Average time through PostgreSQL protocol
- **Overhead**: Percentage difference between the two
- **Count**: Number of operations performed
- **Total time**: Cumulative time for all operations

Lower overhead percentages indicate better protocol translation efficiency.

## Tips for Accurate Benchmarking

1. **Use Release Mode**: Always compile with `--release` for accurate measurements
2. **Default Settings**: Benchmarks use Unix sockets and in-memory databases by default for minimal overhead
3. **TCP Testing**: Use `--tcp` to measure TCP/IP networking overhead
4. **File-Based Testing**: Use `--file-based` when you need to include disk I/O in measurements
5. **Multiple Runs**: Run benchmarks multiple times to account for system variability
6. **Sufficient Iterations**: Use at least 1000 operations for meaningful averages
7. **System Load**: Run on a quiet system for consistent results

## Connection Modes Comparison

- **Unix Socket (default)**: Local-only connection via filesystem socket, lowest latency
- **TCP**: Standard network connection, includes TCP/IP overhead
- **In-Memory (default)**: SQLite database in RAM, eliminates disk I/O
- **File-Based**: SQLite database on disk, includes disk I/O overhead